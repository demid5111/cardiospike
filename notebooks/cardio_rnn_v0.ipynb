{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cardio_rnn_v0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCRvbEjoppx0",
        "outputId": "3531f45a-980d-4022-c9c8-89df97e07fd3"
      },
      "source": [
        "#https://drive.google.com/file/d/1EVwP6MUQAeSnGM-ywBRHspCn_OWEfzJN/view?usp=sharing\n",
        "!curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id=1EVwP6MUQAeSnGM-ywBRHspCn_OWEfzJN\" > /dev/null\n",
        "!curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=`awk '/download/ {print $NF}' ./cookie`&id=1EVwP6MUQAeSnGM-ywBRHspCn_OWEfzJN\" -o train.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   1136      0 --:--:-- --:--:-- --:--:--  1139\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100  955k  100  955k    0     0   766k      0  0:00:01  0:00:01 --:--:--  766k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGCxbyAlM7Hc"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "T_Xf4egHNAk-",
        "outputId": "56e9e337-5949-4513-8441-9164f1f16fd1"
      },
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>time</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>800</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>780</td>\n",
              "      <td>780</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1572</td>\n",
              "      <td>792</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2392</td>\n",
              "      <td>820</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>3196</td>\n",
              "      <td>804</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  time    x  y\n",
              "0   1     0  800  0\n",
              "1   1   780  780  0\n",
              "2   1  1572  792  0\n",
              "3   1  2392  820  0\n",
              "4   1  3196  804  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUdZ_3RoNiji",
        "outputId": "4ad68110-a2a6-4adc-ef2a-9b01634e3fcc"
      },
      "source": [
        "df['marker'] = np.multiply(df[['id','y']].groupby('id').agg(np.cumsum).values.ravel(), df['y'].values)\n",
        "df['start'] = ((df['y'].shift(1, fill_value=0) == 0).values & (df['y'] == 1)).values\n",
        "df['end'] = ((df['y'].shift(-1, fill_value=0) == 0).values & (df['y'] == 1)).values\n",
        "\n",
        "q = df.loc[df['end'],'marker'] - df.loc[df['end'],'start']\n",
        "print('аномалий: ', q.shape[0], 'средняя длина: ', int(q.mean()*100.0)*0.01, 'min: ', q.min(), 'max: ', q.max())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "аномалий:  791 средняя длина:  25.060000000000002 min:  6 max:  81\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "wH4pJnQwTsw4",
        "outputId": "443ca9f2-d03e-4eb0-d62f-57dc3c8f1faf"
      },
      "source": [
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "for q in [111]:\n",
        "    t = df.loc[df['id'] == q].sort_values('time').reset_index(drop=True)\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=t['time'], y=t['x'] - t['x'].mean(),\n",
        "                        mode='lines',\n",
        "                        name='lines'))\n",
        "    qt = t.loc[t.y==1].reset_index(drop=True)\n",
        "    fig.add_trace(go.Scatter(x=qt['time'], y=qt['x'] - t['x'].mean(),\n",
        "                        mode='markers', name='markers'))\n",
        "    print(t.x.mean())\n",
        "    fig.show()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "650.987012987013\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"5cdf15db-130d-4352-8acc-04e6ed402734\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"5cdf15db-130d-4352-8acc-04e6ed402734\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '5cdf15db-130d-4352-8acc-04e6ed402734',\n",
              "                        [{\"mode\": \"lines\", \"name\": \"lines\", \"type\": \"scatter\", \"x\": [0, 600, 1240, 2516, 3156, 3788, 4476, 5068, 5712, 6352, 6996, 7636, 8268, 8904, 9532, 10156, 10784, 11456, 12024, 12648, 13268, 13880, 14496, 15160, 15728, 16344, 17024, 17600, 18224, 18856, 19484, 20112, 20752, 21432, 22012, 22640, 23268, 23928, 24500, 25120, 25736, 26356, 27024, 27592, 28208, 28832, 29448, 30060, 30680, 31292, 31940, 32500, 33692, 34288, 34884, 35480, 36084, 36688, 37288, 37896, 38508, 39116, 39724, 40344, 41020, 41588, 42212, 42892, 43460, 44092, 44724, 45400, 46028, 46596, 47228, 47900, 48472, 49088, 49704, 50312, 50924, 51536, 52144, 52744, 53348, 54552, 55148, 55744, 56336, 56932, 57536, 58144, 58768, 59404, 60036, 60680, 61340, 62040, 62640, 63300, 64620, 65272, 65924, 66568, 67216, 67856, 68492, 69132, 69780, 70420, 71056, 71692, 72324, 73608, 74240, 74888, 75532, 76172, 76864, 77456, 78092, 79364, 80040, 80620, 81252, 81884, 82572, 83216, 83816, 84468, 85124, 85832, 85944, 86444, 87116, 87824, 88432, 89084, 89724, 89956, 90360, 91036, 91608, 92220, 92860, 93480, 94708, 95320, 96540, 97144, 97792, 98348, 98952, 99564], \"y\": [37.01298701298697, -50.98701298701303, -10.987012987013031, 625.012987012987, -10.987012987013031, -18.98701298701303, 37.01298701298697, -58.98701298701303, -6.987012987013031, -10.987012987013031, -6.987012987013031, -10.987012987013031, -18.98701298701303, -14.987012987013031, -22.98701298701303, -26.98701298701303, -22.98701298701303, 21.01298701298697, -82.98701298701303, -26.98701298701303, -30.98701298701303, -38.98701298701303, -34.98701298701303, 13.012987012986969, -82.98701298701303, -34.98701298701303, 29.01298701298697, -74.98701298701303, -26.98701298701303, -18.98701298701303, -22.98701298701303, -22.98701298701303, -10.987012987013031, 29.01298701298697, -70.98701298701303, -22.98701298701303, -22.98701298701303, 9.012987012986969, -78.98701298701303, -30.98701298701303, -34.98701298701303, -30.98701298701303, 17.01298701298697, -82.98701298701303, -34.98701298701303, -26.98701298701303, -34.98701298701303, -38.98701298701303, -30.98701298701303, -38.98701298701303, -2.9870129870130313, -90.98701298701303, 541.012987012987, -54.98701298701303, -54.98701298701303, -54.98701298701303, -46.98701298701303, -46.98701298701303, -50.98701298701303, -42.98701298701303, -38.98701298701303, -42.98701298701303, -42.98701298701303, -30.98701298701303, 25.01298701298697, -82.98701298701303, -26.98701298701303, 29.01298701298697, -82.98701298701303, -18.98701298701303, -18.98701298701303, 25.01298701298697, -22.98701298701303, -82.98701298701303, -18.98701298701303, 21.01298701298697, -78.98701298701303, -34.98701298701303, -34.98701298701303, -42.98701298701303, -38.98701298701303, -38.98701298701303, -42.98701298701303, -50.98701298701303, -46.98701298701303, 553.012987012987, -54.98701298701303, -54.98701298701303, -58.98701298701303, -54.98701298701303, -46.98701298701303, -42.98701298701303, -26.98701298701303, -14.987012987013031, -18.98701298701303, -6.987012987013031, 9.012987012986969, 49.01298701298697, -50.98701298701303, 9.012987012986969, 669.012987012987, 1.0129870129869687, 1.0129870129869687, -6.987012987013031, -2.9870129870130313, -10.987012987013031, -14.987012987013031, -10.987012987013031, -2.9870129870130313, -10.987012987013031, -14.987012987013031, -14.987012987013031, -18.98701298701303, 633.012987012987, -18.98701298701303, -2.9870129870130313, -6.987012987013031, -10.987012987013031, 41.01298701298697, -58.98701298701303, -14.987012987013031, 621.012987012987, 25.01298701298697, -70.98701298701303, -18.98701298701303, -18.98701298701303, 37.01298701298697, -6.987012987013031, -50.98701298701303, 1.0129870129869687, 5.012987012986969, 57.01298701298697, -538.987012987013, -150.98701298701303, 21.01298701298697, 57.01298701298697, -42.98701298701303, 1.0129870129869687, -10.987012987013031, -418.98701298701303, -246.98701298701303, 25.01298701298697, -78.98701298701303, -38.98701298701303, -10.987012987013031, -30.98701298701303, 577.012987012987, -38.98701298701303, 569.012987012987, -46.98701298701303, -2.9870129870130313, -94.98701298701303, -46.98701298701303, -38.98701298701303]}, {\"mode\": \"markers\", \"name\": \"markers\", \"type\": \"scatter\", \"x\": [3156, 3788, 4476, 5068, 5712, 6352, 8904, 9532, 10156, 10784, 11456, 12024, 12648, 13268, 18856, 19484, 20112, 20752, 21432, 22012, 22640, 23268, 25120, 25736, 26356, 27024, 27592, 28208, 28832, 29448], \"y\": [-10.987012987013031, -18.98701298701303, 37.01298701298697, -58.98701298701303, -6.987012987013031, -10.987012987013031, -14.987012987013031, -22.98701298701303, -26.98701298701303, -22.98701298701303, 21.01298701298697, -82.98701298701303, -26.98701298701303, -30.98701298701303, -18.98701298701303, -22.98701298701303, -22.98701298701303, -10.987012987013031, 29.01298701298697, -70.98701298701303, -22.98701298701303, -22.98701298701303, -30.98701298701303, -34.98701298701303, -30.98701298701303, 17.01298701298697, -82.98701298701303, -34.98701298701303, -26.98701298701303, -34.98701298701303]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5cdf15db-130d-4352-8acc-04e6ed402734');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ahkhIR1Z5c9"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "def scale_ts(vls):\n",
        "    sc = StandardScaler()\n",
        "    return sc.fit_transform(vls.reshape(-1,1)).ravel()\n",
        "def scale_time_ts(vls):\n",
        "    sc = MinMaxScaler()\n",
        "    return sc.fit_transform(vls.reshape(-1,1)).ravel()\n",
        "\n",
        "class CardioDataset(Dataset):\n",
        "    def __init__(self, df, win_size=32):\n",
        "        self.df = df.sort_values(['id','time']).reset_index(drop=True).copy()\n",
        "        self.df['time'] = df.groupby('id')['time'].agg('diff').fillna(0).values\n",
        "        self.df['time'] = scale_time_ts(self.df['time'].values)\n",
        "        self.win_size = win_size\n",
        "\n",
        "        self.point_indexes = []\n",
        "        self.win_lens = []\n",
        "        dfs = []\n",
        "        total_len = 0\n",
        "        for q,qdf in self.df.groupby('id'):\n",
        "            qdf['x'] = scale_ts(qdf['x'].values)\n",
        "            for i in range(max(1, qdf.shape[0] - win_size + 1)):\n",
        "                self.point_indexes.append(i + total_len)\n",
        "                if i + win_size > qdf.shape[0]:\n",
        "                    self.win_lens.append(qdf.shape[0] - i)\n",
        "                else:\n",
        "                    self.win_lens.append(win_size)\n",
        "            total_len += qdf.shape[0]\n",
        "            dfs.append(qdf)\n",
        "        self.df = pd.concat(dfs, ignore_index=True).reset_index(drop=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.point_indexes)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        i0 = self.point_indexes[idx]\n",
        "        i1 = i0 + self.win_lens[idx]\n",
        "\n",
        "        x_mat = np.zeros((self.win_size,2))\n",
        "        y_mat = np.zeros(self.win_size)\n",
        "        x_mat[-self.win_lens[idx]:,0] = self.df.iloc[i0:i1].x.values\n",
        "        x_mat[-self.win_lens[idx]:,1] = self.df.iloc[i0:i1].time.values\n",
        "        y_mat[-self.win_lens[idx]:] = self.df.iloc[i0:i1].y.values\n",
        "        \n",
        "        return {\"x\": x_mat,\n",
        "                \"y\": y_mat,\n",
        "                \"start\": i0,\n",
        "                \"end\": i1\n",
        "               }"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsEg7OS_fzsV"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "class CardioRnn(nn.Module):\n",
        "    def __init__(self, win_size, output_size, rnn_units = 32):\n",
        "        super().__init__()\n",
        "        self._gru = nn.GRU(input_size=2, \n",
        "                           hidden_size=rnn_units, \n",
        "                           batch_first=True, \n",
        "                           bidirectional=True)\n",
        "\n",
        "        self._head = nn.Linear(in_features = 4 * rnn_units, \n",
        "                               out_features=output_size)\n",
        "        \n",
        "        self.fcdrop2 = nn.Dropout(p=0.3)\n",
        "        \n",
        "    def forward(self, x_feats):\n",
        "        encoded, _ = self._gru(x_feats)\n",
        "        x2 = torch.max(encoded, axis=1).values\n",
        "        x2 = torch.squeeze(x2)\n",
        "\n",
        "        x3 = torch.mean(encoded, axis=1)\n",
        "        x3 = torch.squeeze(x3)\n",
        "\n",
        "        x = torch.cat([x2,x3],-1)\n",
        "        x = F.relu(x)\n",
        "        x = self.fcdrop2(x)\n",
        "        x = self._head(x)\n",
        "        return x"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51dYrZWih7yb",
        "outputId": "495a1392-00f3-4c6a-8160-a7682a1bb985"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import RandomSampler, SequentialSampler\n",
        "\n",
        "model = CardioRnn(32, 32).to(device)\n",
        "\n",
        "ds = CardioDataset(df, 32)\n",
        "print(len(ds))\n",
        "train_sampler = SequentialSampler(ds)\n",
        "batch_size = 1\n",
        "train_dl = DataLoader(ds, sampler=train_sampler, batch_size=batch_size, num_workers=2)\n",
        "for x in train_dl:\n",
        "    print(model(x['x'].float().to(device)))\n",
        "    break"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53388\n",
            "tensor([ 0.0927, -0.0028, -0.1356,  0.2113,  0.1264, -0.1228, -0.0356, -0.2024,\n",
            "         0.1881, -0.3333, -0.0603, -0.1007,  0.1015, -0.1638, -0.1082,  0.1072,\n",
            "        -0.0653, -0.2886,  0.0441,  0.1270,  0.0874, -0.1646, -0.0966, -0.2795,\n",
            "         0.0826, -0.1080, -0.2170,  0.0131,  0.1661, -0.0356, -0.0217,  0.2447],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vACws6kfmzlF"
      },
      "source": [
        "from sklearn.metrics import roc_curve, precision_recall_curve, f1_score\n",
        "\n",
        "def threshold_search(y_true, y_proba):\n",
        "    precision , recall, thresholds = precision_recall_curve(y_true, y_proba)\n",
        "    thresholds = np.append(thresholds, 1.001) \n",
        "    F = 2 / (1/precision + 1/recall)\n",
        "    best_score = np.max(F)\n",
        "    best_th = thresholds[np.argmax(F)]\n",
        "    return best_th , best_score"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ep0hOJh5o1Ph",
        "outputId": "d01f8587-e9d7-49c2-8696-d9235d4d70df"
      },
      "source": [
        "%%writefile lookahead.py\n",
        "# Lookahead implementation from https://github.com/rwightman/pytorch-image-models/blob/master/timm/optim/lookahead.py\n",
        "\n",
        "\"\"\" Lookahead Optimizer Wrapper.\n",
        "Implementation modified from: https://github.com/alphadl/lookahead.pytorch\n",
        "Paper: `Lookahead Optimizer: k steps forward, 1 step back` - https://arxiv.org/abs/1907.08610\n",
        "\"\"\"\n",
        "import torch\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from collections import defaultdict\n",
        "\n",
        "class Lookahead(Optimizer):\n",
        "    def __init__(self, base_optimizer, alpha=0.5, k=6):\n",
        "        if not 0.0 <= alpha <= 1.0:\n",
        "            raise ValueError(f'Invalid slow update rate: {alpha}')\n",
        "        if not 1 <= k:\n",
        "            raise ValueError(f'Invalid lookahead steps: {k}')\n",
        "        defaults = dict(lookahead_alpha=alpha, lookahead_k=k, lookahead_step=0)\n",
        "        self.base_optimizer = base_optimizer\n",
        "        self.param_groups = self.base_optimizer.param_groups\n",
        "        self.defaults = base_optimizer.defaults\n",
        "        self.defaults.update(defaults)\n",
        "        self.state = defaultdict(dict)\n",
        "        # manually add our defaults to the param groups\n",
        "        for name, default in defaults.items():\n",
        "            for group in self.param_groups:\n",
        "                group.setdefault(name, default)\n",
        "\n",
        "    def update_slow(self, group):\n",
        "        for fast_p in group[\"params\"]:\n",
        "            if fast_p.grad is None:\n",
        "                continue\n",
        "            param_state = self.state[fast_p]\n",
        "            if 'slow_buffer' not in param_state:\n",
        "                param_state['slow_buffer'] = torch.empty_like(fast_p.data)\n",
        "                param_state['slow_buffer'].copy_(fast_p.data)\n",
        "            slow = param_state['slow_buffer']\n",
        "            slow.add_(group['lookahead_alpha'], fast_p.data - slow)\n",
        "            fast_p.data.copy_(slow)\n",
        "\n",
        "    def sync_lookahead(self):\n",
        "        for group in self.param_groups:\n",
        "            self.update_slow(group)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        # print(self.k)\n",
        "        #assert id(self.param_groups) == id(self.base_optimizer.param_groups)\n",
        "        loss = self.base_optimizer.step(closure)\n",
        "        for group in self.param_groups:\n",
        "            group['lookahead_step'] += 1\n",
        "            if group['lookahead_step'] % group['lookahead_k'] == 0:\n",
        "                self.update_slow(group)\n",
        "        return loss\n",
        "\n",
        "    def state_dict(self):\n",
        "        fast_state_dict = self.base_optimizer.state_dict()\n",
        "        slow_state = {\n",
        "            (id(k) if isinstance(k, torch.Tensor) else k): v\n",
        "            for k, v in self.state.items()\n",
        "        }\n",
        "        fast_state = fast_state_dict['state']\n",
        "        param_groups = fast_state_dict['param_groups']\n",
        "        return {\n",
        "            'state': fast_state,\n",
        "            'slow_state': slow_state,\n",
        "            'param_groups': param_groups,\n",
        "        }\n",
        "\n",
        "    def load_state_dict(self, state_dict):\n",
        "        fast_state_dict = {\n",
        "            'state': state_dict['state'],\n",
        "            'param_groups': state_dict['param_groups'],\n",
        "        }\n",
        "        self.base_optimizer.load_state_dict(fast_state_dict)\n",
        "\n",
        "        # We want to restore the slow state, but share param_groups reference\n",
        "        # with base_optimizer. This is a bit redundant but least code\n",
        "        slow_state_new = False\n",
        "        if 'slow_state' not in state_dict:\n",
        "            print('Loading state_dict from optimizer without Lookahead applied.')\n",
        "            state_dict['slow_state'] = defaultdict(dict)\n",
        "            slow_state_new = True\n",
        "        slow_state_dict = {\n",
        "            'state': state_dict['slow_state'],\n",
        "            'param_groups': state_dict['param_groups'],  # this is pointless but saves code\n",
        "        }\n",
        "        super(Lookahead, self).load_state_dict(slow_state_dict)\n",
        "        self.param_groups = self.base_optimizer.param_groups  # make both ref same container\n",
        "        if slow_state_new:\n",
        "            # reapply defaults to catch missing lookahead specific ones\n",
        "            for name, default in self.defaults.items():\n",
        "                for group in self.param_groups:\n",
        "                    group.setdefault(name, default)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing lookahead.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvnXUf0To6Lu",
        "outputId": "9c95407f-d89a-44c3-c9ae-6ab635ced6d5"
      },
      "source": [
        "%%writefile ralamb.py\n",
        "import torch, math\n",
        "from torch.optim.optimizer import Optimizer\n",
        "\n",
        "# RAdam + LARS\n",
        "class Ralamb(Optimizer):\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
        "        self.buffer = [[None, None, None] for ind in range(10)]\n",
        "        super(Ralamb, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(Ralamb, self).__setstate__(state)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data.float()\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError('Ralamb does not support sparse gradients')\n",
        "\n",
        "                p_data_fp32 = p.data.float()\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
        "                else:\n",
        "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                # m_t\n",
        "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "                # v_t\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "\n",
        "                state['step'] += 1\n",
        "                buffered = self.buffer[int(state['step'] % 10)]\n",
        "\n",
        "                if state['step'] == buffered[0]:\n",
        "                    N_sma, radam_step_size = buffered[1], buffered[2]\n",
        "                else:\n",
        "                    buffered[0] = state['step']\n",
        "                    beta2_t = beta2 ** state['step']\n",
        "                    N_sma_max = 2 / (1 - beta2) - 1\n",
        "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
        "                    buffered[1] = N_sma\n",
        "\n",
        "                    # more conservative since it's an approximated value\n",
        "                    if N_sma >= 5:\n",
        "                        radam_step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
        "                    else:\n",
        "                        radam_step_size = 1.0 / (1 - beta1 ** state['step'])\n",
        "                    buffered[2] = radam_step_size\n",
        "\n",
        "                if group['weight_decay'] != 0:\n",
        "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
        "\n",
        "                # more conservative since it's an approximated value\n",
        "                radam_step = p_data_fp32.clone()\n",
        "                if N_sma >= 5:\n",
        "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "                    radam_step.addcdiv_(-radam_step_size * group['lr'], exp_avg, denom)\n",
        "                else:\n",
        "                    radam_step.add_(-radam_step_size * group['lr'], exp_avg)\n",
        "\n",
        "                radam_norm = radam_step.pow(2).sum().sqrt()\n",
        "                weight_norm = p.data.pow(2).sum().sqrt().clamp(0, 10)\n",
        "                if weight_norm == 0 or radam_norm == 0:\n",
        "                    trust_ratio = 1\n",
        "                else:\n",
        "                    trust_ratio = weight_norm / radam_norm\n",
        "\n",
        "                state['weight_norm'] = weight_norm\n",
        "                state['adam_norm'] = radam_norm\n",
        "                state['trust_ratio'] = trust_ratio\n",
        "\n",
        "                if N_sma >= 5:\n",
        "                    p_data_fp32.addcdiv_(-radam_step_size * group['lr'] * trust_ratio, exp_avg, denom)\n",
        "                else:\n",
        "                    p_data_fp32.add_(-radam_step_size * group['lr'] * trust_ratio, exp_avg)\n",
        "\n",
        "                p.data.copy_(p_data_fp32)\n",
        "\n",
        "        return loss"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing ralamb.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkeKVWauo8az"
      },
      "source": [
        "from lookahead import *\n",
        "from ralamb import * \n",
        "\n",
        "def Over9000(params, alpha=0.5, k=6, *args, **kwargs):\n",
        "     ralamb = Ralamb(params, *args, **kwargs)\n",
        "     return Lookahead(ralamb, alpha, k)\n",
        "\n",
        "RangerLars = Over9000"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRmvgyJ3NHen",
        "outputId": "0a2264a3-819b-4df4-af29-f84cefbe3441"
      },
      "source": [
        "import joblib \n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import KFold\n",
        "import tqdm\n",
        "\n",
        "WIN_SIZE = 32\n",
        "RNN_UNITS = 32\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "ifold = 0\n",
        "for tr_id, va_id in kf.split(df['id'].unique()):\n",
        "    train_df = df.loc[df['id'].isin(tr_id)].reset_index(drop=True)\n",
        "    valid_df = df.loc[df['id'].isin(va_id)].reset_index(drop=True)\n",
        "\n",
        "    train_ds = CardioDataset(train_df, WIN_SIZE)\n",
        "    valid_ds = CardioDataset(valid_df, WIN_SIZE)\n",
        "\n",
        "    train_sampler = RandomSampler(train_ds)\n",
        "    valid_sampler = SequentialSampler(valid_ds)\n",
        "    batch_size = 256\n",
        "    train_dl = DataLoader(train_ds, sampler=train_sampler, batch_size=batch_size, num_workers=2)\n",
        "    valid_dl = DataLoader(valid_ds, sampler=valid_sampler, batch_size=batch_size, num_workers=2)\n",
        "\n",
        "    model = CardioRnn(WIN_SIZE, WIN_SIZE, rnn_units=RNN_UNITS).to(device)\n",
        "\n",
        "    nepochs = 5\n",
        "    criterion = torch.nn.BCEWithLogitsLoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(),\n",
        "                       lr = 1e-4, eps=1e-6                           \n",
        "                       )\n",
        "    #optimizer = RangerLars(model.parameters(), lr=3e-4)\n",
        "    for epoch in range(nepochs):\n",
        "        model.train();\n",
        "        optimizer.zero_grad()\n",
        "        i = 0\n",
        "        for x in train_dl:\n",
        "            out = model(x['x'].float().to(device))\n",
        "            loss = criterion(out, x['y'].float().to(device)) \n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 10.0)\n",
        "            optimizer.step() \n",
        "            optimizer.zero_grad()\n",
        "            i += 1\n",
        "        #torch.save(model.state_dict(), 'model_'+str(epoch) + '.pth')\n",
        "    \n",
        "        valid_df_predict = np.zeros((valid_df.shape[0],WIN_SIZE))\n",
        "        model.eval();\n",
        "        for x in valid_dl:\n",
        "            out = model(x['x'].float().to(device))\n",
        "            out = torch.nn.Softmax(dim=1)(out)\n",
        "            for j in range(x['x'].shape[0]):\n",
        "                i0,i1 = x[\"start\"][j],x[\"end\"][j]\n",
        "                s = i1 - i0\n",
        "                valid_df_predict[i0:i1, i0 % WIN_SIZE] = out[j].detach().cpu().numpy()[-s:]\n",
        "        y_proba = np.amax(valid_df_predict, 1)\n",
        "        y_true = valid_df.y.values\n",
        "\n",
        "        best_th , best_score = threshold_search(y_true, y_proba)\n",
        "        print('fold', ifold, 'epoch', epoch, 'best_th', best_th, 'f1-score', best_score)\n",
        "\n",
        "    ifold += 1"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 0 epoch 0 best_th 0.035379305481910706 f1-score 0.24848382749326148\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 0 epoch 1 best_th 0.031115170568227768 f1-score 0.2492894164855375\n",
            "fold 0 epoch 2 best_th 0.029670758172869682 f1-score 0.2500834724540902\n",
            "fold 0 epoch 3 best_th 0.031222067773342133 f1-score 0.251602023608769\n",
            "fold 0 epoch 4 best_th 0.031076762825250626 f1-score 0.2514131443516409\n",
            "fold 1 epoch 0 best_th 0.04119512066245079 f1-score 0.19968635650810246\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 1 epoch 1 best_th 0.03765447437763214 f1-score 0.1966414224563714\n",
            "fold 1 epoch 2 best_th 0.03930889815092087 f1-score 0.2086720867208672\n",
            "fold 1 epoch 3 best_th 0.03362691029906273 f1-score 0.20515695067264575\n",
            "fold 1 epoch 4 best_th 0.031361132860183716 f1-score 0.19757203842049095\n",
            "fold 2 epoch 0 best_th 0.032578855752944946 f1-score 0.20641520641520641\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 2 epoch 1 best_th 0.032595112919807434 f1-score 0.20651204281891172\n",
            "fold 2 epoch 2 best_th 0.03218702971935272 f1-score 0.20651441407712468\n",
            "fold 2 epoch 3 best_th 0.03173034265637398 f1-score 0.20621192750244416\n",
            "fold 2 epoch 4 best_th 0.031410206109285355 f1-score 0.20606788825473119\n",
            "fold 3 epoch 0 best_th 0.03376809135079384 f1-score 0.4406779661016949\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 3 epoch 1 best_th 0.0397295206785202 f1-score 0.45027322404371595\n",
            "fold 3 epoch 2 best_th 0.03178536519408226 f1-score 0.4468500977296647\n",
            "fold 3 epoch 3 best_th 0.03098348341882229 f1-score 0.44311556286440423\n",
            "fold 3 epoch 4 best_th 0.0308694988489151 f1-score 0.4470059880239521\n",
            "fold 4 epoch 0 best_th 0.036863062530756 f1-score 0.267772148011669\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold 4 epoch 1 best_th 0.03777872398495674 f1-score 0.26151136458944896\n",
            "fold 4 epoch 2 best_th 0.03258337825536728 f1-score 0.2604992903064206\n",
            "fold 4 epoch 3 best_th 0.030974939465522766 f1-score 0.26006655574043264\n",
            "fold 4 epoch 4 best_th 0.03108399361371994 f1-score 0.26012044161927067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NP503HubrK36"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
